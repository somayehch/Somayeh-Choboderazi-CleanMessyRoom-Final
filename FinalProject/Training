{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huMAga5nT3Lb",
        "outputId": "07efd13f-b3d3-4039-e4f9-39bc96caee20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# We import the Google Drive integration tool for Google Colab.\n",
        "# This allows us to access files stored in our Google Drive account.\n",
        "from google.colab import drive\n",
        "\n",
        "# This command connects (mounts) your Google Drive into the Colab environment.\n",
        "# After running it the first time, you get a link to authorize access.\n",
        "# Once authorized, you can read and write files directly to your Drive.\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the start of my training notebook, I mounted my Google Drive so I could access my dataset and save my trained model safely. Colab resets often, which means files inside it can disappear, but Drive keeps everything permanent. By mounting Drive here, I made sure my images and model weights could be loaded directly, and I ensured that anything I save later won’t be lost. This step is essential so the rest of the notebook works smoothly without missing files."
      ],
      "metadata": {
        "id": "fk317yjPBNG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "4CfBK-eTVaCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, I imported all the core tools I needed to build and train my deep learning model. PyTorch handles neural networks, optimization, and tensors. torchvision gives me access to the pretrained ResNet50 model and image transformations. PIL helps me load and manipulate images. tqdm provides progress bars during training so I can easily monitor progress. matplotlib allows me to visualize results later. Importing everything upfront helps avoid errors later and prepares the environment for the full training pipeline."
      ],
      "metadata": {
        "id": "hd_ghcm1BpTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the folder where your dataset is stored in Google Drive.\n",
        "DATASET_PATH = \"/content/drive/MyDrive/clean_vs_messy_dataset/raw/\"\n"
      ],
      "metadata": {
        "id": "q6lD6eZNVff7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I set the location of my dataset—the folder where all my clean and messy images are stored. By defining this path once, I can reuse it throughout the notebook without repeating long file names. This makes my code cleaner and easier to update if anything changes."
      ],
      "metadata": {
        "id": "WX4CfHg5Bv4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RoomDataset(Dataset):\n",
        "    def __init__(self, clean_folder, messy_folder, transform=None):\n",
        "        # We list all image file paths inside the clean and messy folders.\n",
        "        self.clean_images = [os.path.join(clean_folder, f) for f in os.listdir(clean_folder)]\n",
        "        self.messy_images = [os.path.join(messy_folder, f) for f in os.listdir(messy_folder)]\n",
        "\n",
        "        # We combine clean + messy into one list with labels:\n",
        "        # clean = 0, messy = 1\n",
        "        self.data = [(img, 0) for img in self.clean_images] + \\\n",
        "                    [(img, 1) for img in self.messy_images]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns total number of images\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Reads an image and returns (image_tensor, label)\n",
        "        img_path, label = self.data[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "oPR0HO2LVi0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell defines my custom dataset class, which controls how images are loaded during training. I combined clean room images with messy room images and assigned labels to them (0 for clean, 1 for messy). When the model needs an image, this class opens it, converts it into a PyTorch tensor, applies my transformations, and returns the image along with its correct label. I created this dataset class so that PyTorch can easily manage all my images and feed them into the neural network in an organized and structured way."
      ],
      "metadata": {
        "id": "wiVsdeniB552"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7GjwGIbXnRK",
        "outputId": "a522ab79-8aa8-42b2-ab23-a059a52d3b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell simply lists the contents of the /content directory. I used this to verify that my environment contains the expected folders, such as the temporary data folder or my mounted Google Drive. It is mainly a quick check to ensure everything is set up correctly before moving forward."
      ],
      "metadata": {
        "id": "l1ASX3m_B_yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing used for ResNet50\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ResNet50 expects 224x224\n",
        "    transforms.ToTensor(),          # Convert the image to a tensor\n",
        "    transforms.Normalize(           # Standard normalization for ImageNet models\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Create the dataset using the class defined above\n",
        "dataset = RoomDataset(\n",
        "    clean_folder=DATASET_PATH + \"clean\",\n",
        "    messy_folder=DATASET_PATH + \"messy\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# Load the dataset into batches of images\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
      ],
      "metadata": {
        "id": "NiiPDNdzVmMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, I prepared the images so they match what ResNet50 expects. I resized them to 224x224, turned them into tensors, and normalized them using ImageNet values. After that, I created my dataset object using the RoomDataset class and loaded the clean/messy folders. Finally, I wrapped everything in a DataLoader so the images are delivered in batches of 16 during training. Shuffling helps the model learn better by mixing the image order."
      ],
      "metadata": {
        "id": "WOqNREqzCHsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained ResNet50\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Replace the last fully connected layer with 2 outputs:\n",
        "# 0 = clean, 1 = messy\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "# Choose GPU if available (much faster!)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function + optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjo7gd-jVs0r",
        "outputId": "39a38f04-73d5-4181-b74d-28a85842528a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 119MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I loaded the pretrained ResNet50 model, which already understands general image structures thanks to training on ImageNet. I replaced its final layer so it predicts two classes instead of 1000. Then I moved the model to GPU if available to speed up training. Finally, I set up the loss function to measure errors during training and chose the Adam optimizer, which adjusts the model’s weights to improve predictions. This cell sets up the entire learning engine."
      ],
      "metadata": {
        "id": "WZQXwfk6Cjvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5  # You can increase later if needed\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()          # Clear old gradients\n",
        "        outputs = model(images)        # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compare prediction to actual label\n",
        "        loss.backward()                # Backpropagation\n",
        "        optimizer.step()               # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {running_loss:.4f} - Accuracy: {epoch_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_dJ5si_Vtpy",
        "outputId": "72446a97-80fa-4746-a7ed-cdba27a5114b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [06:10<00:00, 14.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 7.5976 - Accuracy: 87.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [04:38<00:00, 11.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Loss: 1.7526 - Accuracy: 97.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [04:35<00:00, 11.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Loss: 1.3557 - Accuracy: 98.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [04:36<00:00, 11.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Loss: 0.2638 - Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [04:39<00:00, 11.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Loss: 0.3757 - Accuracy: 99.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell is where my model actually learned. For each epoch, the model processed every image in the training folder, compared its predictions to the correct labels, and adjusted its weights to improve accuracy. The training loop keeps track of the loss and accuracy so I can see how the model is improving after each pass through the dataset. Over the five epochs, the accuracy steadily increased, showing the model was successfully learning how to tell clean and messy rooms apart."
      ],
      "metadata": {
        "id": "pYL7kacbCs-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"/content/drive/MyDrive/clean_vs_messy_dataset/model_resnet50.pth\"\n",
        "\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "\n",
        "print(\"Model saved to:\", MODEL_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rXsxdWKVyae",
        "outputId": "c3bb66e4-c0a6-434e-c0c1-5e93cbacc130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/clean_vs_messy_dataset/model_resnet50.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After finishing training, I saved my model's learned weights to my Google Drive. This step is very important because it lets me reuse the model later in my demo notebook without retraining it ever again. By saving the .pth file, I preserved the exact version of the model that achieved high accuracy during training."
      ],
      "metadata": {
        "id": "v2rdzanhDgOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "***SUMMARY — CLEAN vs MESSY ROOM TRAINING NOTEBOOK***\n",
        "\n",
        "\n",
        "\n",
        "In this part of my project, I built and trained a deep-learning model that can automatically classify whether a room is clean or messy. I started by mounting my Google Drive inside Google Colab so I could access my dataset and save my trained model safely. Then, I imported all the essential libraries, including PyTorch, torchvision, PIL, and matplotlib, which allowed me to handle data loading, preprocessing, model training, and later visualization.\n",
        "Next, I defined a custom dataset class called RoomDataset. This class organized all my clean and messy room images and assigned labels to them. I also applied preprocessing steps to each image, such as resizing, converting to tensors, and normalizing them, because the pretrained ResNet50 model expects images in a very specific format. After preparing the dataset, I used a PyTorch DataLoader to feed the images into the model in batches, which made the training more efficient.\n",
        "For the model, I chose ResNet50, a powerful convolutional neural network pretrained on ImageNet. I replaced the last layer so it outputs only two classes: clean and messy. I then set up my loss function (CrossEntropyLoss) and optimizer (Adam), and trained the model for 5 epochs. During training, the model learned to recognize patterns in room images, and I monitored the loss and accuracy after each epoch. The accuracy improved significantly and reached almost perfect performance.\n",
        "After training was complete, I saved the model’s weights into my Google Drive so I could use them later in the demo notebook without retraining. This final saved model is what powers my live demo and prediction interface.\n",
        "Overall, this training phase established the core intelligence of my system — teaching the model how to understand room cleanliness from images and making it ready for real-world testing and demonstrations.\n",
        "\n",
        "In this part of my project, I built and trained a deep-learning model that can automatically classify whether a room is clean or messy. I started by mounting my Google Drive inside Google Colab so I could access my dataset and save my trained model safely. Then, I imported all the essential libraries, including PyTorch, torchvision, PIL, and matplotlib, which allowed me to handle data loading, preprocessing, model training, and later visualization.\n",
        "Next, I defined a custom dataset class called RoomDataset. This class organized all my clean and messy room images and assigned labels to them. I also applied preprocessing steps to each image, such as resizing, converting to tensors, and normalizing them, because the pretrained ResNet50 model expects images in a very specific format. After preparing the dataset, I used a PyTorch DataLoader to feed the images into the model in batches, which made the training more efficient.\n",
        "For the model, I chose ResNet50, a powerful convolutional neural network pretrained on ImageNet. I replaced the last layer so it outputs only two classes: clean and messy. I then set up my loss function (CrossEntropyLoss) and optimizer (Adam), and trained the model for 5 epochs. During training, the model learned to recognize patterns in room images, and I monitored the loss and accuracy after each epoch. The accuracy improved significantly and reached almost perfect performance.\n",
        "After training was complete, I saved the model’s weights into my Google Drive so I could use them later in the demo notebook without retraining. This final saved model is what powers my live demo and prediction interface.\n",
        "Overall, this training phase established the core intelligence of my system — teaching the model how to understand room cleanliness from images and making it ready for real-world testing and demonstrations.\n",
        "\n",
        "\n",
        "-----\n",
        "\n"
      ],
      "metadata": {
        "id": "6Xnjscs6D-OW"
      }
    }
  ]
}
