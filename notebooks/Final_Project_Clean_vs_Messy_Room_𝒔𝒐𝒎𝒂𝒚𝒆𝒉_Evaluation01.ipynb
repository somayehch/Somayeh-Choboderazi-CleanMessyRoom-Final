{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAxF37P2jGXj",
        "outputId": "5a5858e4-d534-4b23-ddcf-a9841211a12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, I connected my Google Drive to Colab so I could access my dataset and my trained model directly from Drive. Colab doesn't keep files permanently, so mounting my Drive was the only way to make sure my images and saved weights were available every time I ran the notebook. Once this cell finished running, all my Drive files became visible inside Colab, which allowed the rest of my code to work smoothly."
      ],
      "metadata": {
        "id": "kIilturJ8b7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "siNIJakskIug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I imported all the libraries I needed for the entire project. I brought in PyTorch for deep learning, torchvision for handling image models and transformations, PIL for reading images, sklearn for evaluation metrics, and matplotlib for visualization. Importing these tools upfront prepared my environment, so I didn't run into errors later. This cell didn't perform any processing yet—it simply loaded everything I planned to use."
      ],
      "metadata": {
        "id": "ho8Slyl_8oUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/clean_vs_messy_dataset/raw/\"\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "yUtkumf_kQ6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Define Dataset Path and Image Transformations***\n",
        "\n",
        "\n",
        "\n",
        "In this cell, I set the exact path to my dataset and defined the transformations that each image needed before entering the model. I resized every image to the size ResNet50 expects, converted them into tensors, and normalized them based on ImageNet standards. I did this because the model works best when images follow a consistent format. Without these transformations, the model might misinterpret the pixel values or produce unstable predictions."
      ],
      "metadata": {
        "id": "--axQWHX8xQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RoomDataset(Dataset):\n",
        "    def __init__(self, clean_folder, messy_folder, transform=None):\n",
        "        self.clean_images = [os.path.join(clean_folder, f) for f in os.listdir(clean_folder)]\n",
        "        self.messy_images = [os.path.join(messy_folder, f) for f in os.listdir(messy_folder)]\n",
        "\n",
        "        self.data = [(img, 0) for img in self.clean_images] + \\\n",
        "                    [(img, 1) for img in self.messy_images]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "-UsKTcdJkTUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Create the RoomDataset Class***\n",
        "\n",
        "\n",
        "\n",
        "Here, I created my own custom dataset class to manage how images and labels are loaded. I gathered all image paths from the clean folder and messy folder and assigned labels to them—0 for clean and 1 for messy. When the model asks for an image, this class opens it, applies my transformations, and returns the image paired with its correct label. I built this class so my data would be organized and easy for PyTorch to read during evaluation."
      ],
      "metadata": {
        "id": "ndwJDpWp8-xL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = RoomDataset(\n",
        "    clean_folder=DATASET_PATH + \"clean\",\n",
        "    messy_folder=DATASET_PATH + \"messy\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "eval_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "print(\"Total images for evaluation:\", len(dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyMk93s-kZJ5",
        "outputId": "f5279732-a095-4851-be94-c7a7e5a19b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images for evaluation: 390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Create Dataset and DataLoader***\n",
        "\n",
        "\n",
        "\n",
        "In this cell, I turned my dataset into something PyTorch could work with efficiently. I used the DataLoader to group my images into batches, which made the evaluation faster and more memory-friendly. I didn't shuffle the data because I wasn't training; I just wanted a clean, ordered evaluation. Running this cell also let me check how many total images I had for testing."
      ],
      "metadata": {
        "id": "o0dYOEEl9DJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuild the same ResNet50 architecture\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# Load trained weights from Drive\n",
        "MODEL_PATH = \"/content/drive/MyDrive/clean_vs_messy_dataset/model_resnet50.pth\"\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "print(\"Model loaded and set to eval mode.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3riW9keekg1d",
        "outputId": "d5945f88-0a70-406a-ae8f-fe438b29dcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 134MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and set to eval mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Rebuild ResNet50 Architecture***\n",
        "\n",
        "\n",
        "\n",
        "In this step, I recreated the exact ResNet50 structure I used during training. I loaded the pretrained ImageNet weights and then replaced the final layer with a new one that outputs two classes—clean and messy rooms. I did this because the original ResNet50 predicts 1,000 classes, and I only needed two. Setting up the architecture correctly here was important because the trained weights I planned to load must match this structure perfectly."
      ],
      "metadata": {
        "id": "Cl6zZoCW9UqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():  # No gradients needed during evaluation\n",
        "    for images, labels in tqdm(eval_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "all_labels = np.array(all_labels)\n",
        "all_preds = np.array(all_preds)\n",
        "\n",
        "accuracy = (all_labels == all_preds).mean() * 100\n",
        "print(f\"Evaluation Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5-ZKzTIkn3T",
        "outputId": "ad515ca4-5730-499b-dc1c-facdce792b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [02:20<00:00,  5.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Run Evaluation Loop***\n",
        "\n",
        "\n",
        "\n",
        "In this cell, I passed every image from my dataset through the model to get predictions. I used torch.no_grad() to speed up the process since I wasn’t training. The model gave me two scores for each image, and I selected the class with the higher score. While iterating through all batches, I saved both the true labels and the models predicted labels. This gave me the raw data I needed to measure accuracy and other metrics."
      ],
      "metadata": {
        "id": "LN4ENTMf9bfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"clean\", \"messy\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3vsgQapldpr",
        "outputId": "46f2bf00-2f46-484a-cd29-668816d2456e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[180   0]\n",
            " [  0 210]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       clean       1.00      1.00      1.00       180\n",
            "       messy       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       390\n",
            "   macro avg       1.00      1.00      1.00       390\n",
            "weighted avg       1.00      1.00      1.00       390\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Confusion Matrix and Classification Report***\n",
        "\n",
        "\n",
        "\n",
        "In this cell, I dug deeper into how the model performed. The confusion matrix showed exactly where the model was right or wrong for each class, and the classification report gave me metrics like precision, recall, and F1-score. These numbers helped me understand not just whether the model was accurate, but how it behaved on clean images versus messy ones. Because everything was perfect, all metrics came out as 1.00."
      ],
      "metadata": {
        "id": "xZbMsoQ69jzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "ax.imshow(cm, cmap='Blues')\n",
        "\n",
        "ax.set_xticks([0, 1])\n",
        "ax.set_yticks([0, 1])\n",
        "ax.set_xticklabels(['clean', 'messy'])\n",
        "ax.set_yticklabels(['clean', 'messy'])\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
        "\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('True')\n",
        "ax.set_title('Confusion Matrix')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "XvDWCTaqllFO",
        "outputId": "0d5c7283-b245-48e6-933e-5eaf539f8168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, I visualized the confusion matrix to make the results easier to interpret. Seeing the matrix as a heatmap helped me quickly confirm that all predictions landed on the diagonal line where correct classifications appear. This visual check reassured me that the model didn't make a single mistake."
      ],
      "metadata": {
        "id": "sXzzKyN2-Cbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "\n",
        "\n",
        "***Summary of What I Did in This Evaluation Notebook***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this part of my project, I focused on evaluating how well my clean-vs-messy room classifier performs using the full dataset I created. I began by mounting my Google Drive so I could access the dataset and the trained model safely and consistently. After that, I imported all the necessary libraries for deep learning, image processing, and evaluation. Once everything was ready, I set the exact path to my dataset and prepared the image transformations so each picture would match the format my ResNet50 model expects.\n",
        "Next, I built a custom RoomDataset class that organizes my clean and messy images and assigns the correct labels. I wrapped this dataset inside a DataLoader so the images could be processed efficiently during evaluation. I then rebuilt my original model architecture and loaded my trained weights from Drive, restoring the model exactly as it was during training.\n",
        "With the model loaded, I ran an evaluation loop that passed every single image through the classifier. During this process, I collected all the true labels and the predicted labels so I could measure accuracy and produce deeper metrics. After running through the entire dataset, I calculated the accuracy and then generated a confusion matrix along with a full classification report. These metrics helped me understand not only whether the model was correct, but also how balanced and consistent its predictions were for both clean and messy rooms.\n",
        "Finally, I visualized the confusion matrix to make the results easier to interpret. Seeing all predictions fall perfectly on the diagonal confirmed that my model reached 100% accuracy on this dataset. This evaluation notebook gave me a complete and confident understanding of how well my model performs before using it in the live demo.\n",
        "\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "1MTychcA-FNj"
      }
    }
  ]
}